# About

## How the project started 

The Data Hazards project started 2021.
We (Natalie and Nina) wanted a way to communicate what might go wrong in data science projects, because we were frustrated by the repetitive themes we were seeing in harmful technologies that we talked about in [Data Ethics Club](https://dataethicsclub.com).
We were also concerned that many projects that have significant societal impact do not have those impacts scrutinised by an Ethics Committee, because they do not technically have research participants. 
After that conversation we came up with the idea of Hazard labels for communicating these potential harms, and called them Data Hazards. 
We decided they should be visual, like COSHH chemical hazards are, and that they should be a way for people at all stages of data science technology development to communicate about the same potential outcomes (no matter how far away those outcomes might seem).

You can see [the current Data Hazard labels here](data-hazards).  
You can [read our original proposal here](materials/misc/proposal).  

The image below describes the 'anatomy' of a Data Hazards label.   

```{image} ../images/hazardanatomy.png
:alt: An image of a orange square with a red hexagon in it and the words 'Title', 'Description', 'Examples', 'Safety precautions'. 
```

  
Once we had thought of the original list of Hazards we wanted a way for researchers to think about them in a format that encouraged them to reflect, invite different opinions and make them think more broadly about the potential ethical concerns from their project. 
This led to the development of our workshop format and [all the materials we have since made](materials) for self-reflection and teaching. 
All our resources are designed for re-use by others. 


## Ethos

The Data Hazards are built on the foundations of [standpoint theory](https://en.wikipedia.org/wiki/Standpoint_theory). 
This is an epistemiological theory that knowledge (including in the sciences) is not objective, and that our perspectives are shaped by our lived socio-political experiences. 
This means that ethical problems are not going to have a single correct answer, and that to get a well-rounded understanding of the ethical issues of any new technology we need people from lots of different standpoints to analyse it from their perspective. 
This is the best way we can understand the harms it could possibly cause.
We also need to make sure that we are paying attention to how technology might be more likely to adversely affect people from minoritised backgrounds.

In summary, the Data Hazards exist to prompt discussion, reflection and thought. 
They are not a checkbox exercise, and there is no requirement for a group to come to a consensus. 
In an individual context you will likely come to a conclusion, but someone else may have a different view.
We hope that the Data Hazards discussion and reflective activities will help researchers be aware of a broader variety of potential ethical risks in tech projects, and that ethics is complex, situational and worth discussing.
